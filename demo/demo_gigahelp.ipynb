{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd71a4e7",
   "metadata": {},
   "source": [
    "### Установка и импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5925c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4aa1c",
   "metadata": {},
   "source": [
    "### Функции для gigahelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4817838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gigahelp(url: str, query: str, tag=None, type_parser='bs', driver_path = None, type_query = 'code', auth_token=None) -> str:\n",
    "    \"\"\"url - ссылка на сайт,\n",
    "       query - запрос для GigaChat,\n",
    "       tag - тэг для указания, если html-код страницы большой,\n",
    "       type_parser - 'bs' (html-код) или 'selenium' (JavaScipt)\n",
    "       driver_path - путь к веб-драйверу для selenium\n",
    "       type_query - вид запроса для GigaChat:\n",
    "                    'code' - чтобы GigaChat написал парсер по html-коду \n",
    "                    'question' - режим работы вопрос-ответ\n",
    "       auth_token - токен для подключения к GigaChat, по умолчанию None, но без указания не подключится\n",
    "                    \"\"\"\n",
    "    \n",
    "    \"\"\"Основная функция для выдачи результата по запросу пользователя.\n",
    "\n",
    "    Если нужен обычный запрос, в виде вопроса-подсказки то type_query == 'question',\n",
    "    если нужен парсер по коду html-страницы, то type_query == 'code'\"\"\"\n",
    "\n",
    "    \"\"\"Пример query для type_query = 'code': \n",
    "    \n",
    "       'Напиши парсер на python используя selenium чтобы получить список отзывов\n",
    "      [{'name':'Благодарность сотрудникам за профессионализмб вежливость и скорость решения вопросов',\n",
    "       'full_descr':/services/responses/bank/response/11557227/,\n",
    "       'date':['07.06.2024 20:37', '25.06.2024 10:09']}].\n",
    "        Для поиска элементов используй By.XPATH.'\n",
    "        \n",
    "        Обязательно нужно дать пример того, что хотите получить, какие поля и пример их содержания.\n",
    "        \"\"\"\n",
    "    if type_query == 'question':\n",
    "        return _ask_gigachat(query, auth_token)\n",
    "    if type_query == 'code':\n",
    "        clear_html = _crop_html(url, tag, type_parser, driver_path)\n",
    "        return _ask_gigachat(\"Вот кода сайта: \" + clear_html + query, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7839e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop_html(url: str, tag=None, type_parser='bs', driver_path = None) -> str:\n",
    "    \"\"\"Приватная функция для обрезки html.\n",
    "    Функция для очистки html-кода. Работает по 2-м сценариям, если сайт маленький, то берется весь body от всего html-кода,\n",
    "    очищается от лишних символов и результат затем можно подать на вход GigaChat.\n",
    "    Если код большой, то подается тэг, в котором есть необходимая информация (придется посмотреть в код), далее этот текст\n",
    "    сокращается до 20000 символов (токенов) для экономии кол-ва токенов, которые подаются на вход модели.\"\"\"\n",
    "    if type_parser == 'bs':\n",
    "        if tag==None:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text_with_tags = soup.body.prettify()\n",
    "            lines = text_with_tags.split('\\n')\n",
    "            cleaned_lines = [line for line in lines if 'script' not in line and '$' not in line and 'noindex' not in line and\n",
    "                            '</a>' not in line and '</p>' not in line and '</i>' not in line and\n",
    "                            '<br/>' not in line and '</span>' not in line and '</header>' not in line and '</li>' not in line and\n",
    "                            '</ul>']\n",
    "            cleaned_txt = '\\n'.join(cleaned_lines)\n",
    "            cleaned_txt = cleaned_txt[0:20000]\n",
    "\n",
    "            \n",
    "        else:\n",
    "            cleaned_txt = \"\"\"\"\"\"\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            need_html = soup.body.find_all('div', class_=tag)\n",
    "            for i in need_html:\n",
    "                cleaned_txt += \"\".join(i.prettify())\n",
    "            \n",
    "            cleaned_txt = cleaned_txt[0:20000]\n",
    "            \n",
    "            \n",
    "            \n",
    "        cleaned_txt = re.sub(r\"\\s+\", ' ', cleaned_txt)\n",
    "    \n",
    "    if type_parser == 'selenium':\n",
    "        options=ChromeOptions()\n",
    "        DRIVER = webdriver.Chrome(executable_path=driver_path, options=options)\n",
    "        DRIVER.get(url)\n",
    "        DRIVER.implicitly_wait(1)\n",
    "        \n",
    "        if tag==None:\n",
    "                    \n",
    "            html = DRIVER.find_element_by_tag_name('body').get_attribute('innerHTML')\n",
    "            \n",
    "            DRIVER.quit()\n",
    "            \n",
    "            lines = html.split('\\n')\n",
    "            cleaned_lines = [line for line in lines if 'script' not in line and '$' not in line and 'noindex' not in line and\n",
    "                            '</a>' not in line and '</p>' not in line and '</i>' not in line and\n",
    "                            '<br/>' not in line and '</span>' not in line and '</header>' not in line and '</li>' not in line and\n",
    "                            '</ul>']\n",
    "            cleaned_txt = '\\n'.join(cleaned_lines)\n",
    "            cleaned_txt = cleaned_txt[0:20000]\n",
    "\n",
    "        else:\n",
    "            cleaned_txt = \"\"\"\"\"\"\n",
    "            html = DRIVER.find_elements_by_class_name(tag)\n",
    "            \n",
    "            for i in html:\n",
    "                cleaned_txt += \"\".join(i.get_attribute('innerHTML'))\n",
    "                \n",
    "            DRIVER.quit()\n",
    "            \n",
    "            cleaned_txt = cleaned_txt[0:20000]\n",
    "        \n",
    "        cleaned_txt = re.sub(r'\\s+', ' ', cleaned_txt)\n",
    "    \n",
    "    return cleaned_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd53fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ask_gigachat(query: str, auth_token) -> str:\n",
    "    \"\"\"Запрос к API гигачата.\"\"\"\n",
    "    # Авторизация в сервисе GigaChat\n",
    "    chat = GigaChat(credentials=auth_token,\n",
    "                verify_ssl_certs=False)\n",
    "    messages = [SystemMessage(content=\"\"\"Вы отличный помощник, \n",
    "                который помогает писать парсеры по предоставленному коду html-страницы.\n",
    "                Вы отвечаете только по сути.\n",
    "                Отвечай только на поставленный вопрос, ответ должен быть краткий и подходящий вопросу.\"\"\")]\n",
    "    messages.append(HumanMessage(content=query))\n",
    "    res = chat(messages)\n",
    "    messages.append(res)\n",
    "    # Ответ модели\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ab7ea",
   "metadata": {},
   "source": [
    "### Параметры вводимые пользователем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395d3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL - сайта\n",
    "url = 'https://www.banki.ru/services/responses/bank/sberbank/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b61dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запрос пользователя с примером того, что он хочет достать с сайта\n",
    "query = \"\"\"Напиши парсер на python используя beautiful soup чтобы получить список отзывов\n",
    "           [{'name':'Благодарность сотрудникам за профессионализмб вежливость и скорость решения вопросов',\n",
    "           'full_descr':/services/responses/bank/response/11557227/,\n",
    "           'date':['07.06.2024 20:37', '25.06.2024 10:09']}].\n",
    "           Для начала нужно найти все элементы с class=la8a5ef73.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178995ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токен, полученный по интсрукции\n",
    "token = 'your token'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b28401",
   "metadata": {},
   "source": [
    "### Использование функции в режиме code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c926776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для начала, нам нужно найти все элементы с классом `la8a5ef73`. Это могут быть как заголовки отзывов, так и сами отзывы.\n",
      "\n",
      "Вот пример кода на Python, который использует Beautiful Soup для извлечения отзывов:\n",
      "\n",
      "```python\n",
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "\n",
      "url = \"https://www.sberbank.ru/ru/services/responses/bank/allReviewsPage\"\n",
      "page = requests.get(url).text\n",
      "soup = BeautifulSoup(page, \"html.parser\")\n",
      "\n",
      "# Находим все элементы с классом 'la8a5ef73'\n",
      "reviews = soup.find_all(\"div\", class_=\"la8a5ef73\")\n",
      "\n",
      "# Создаем список отзывов\n",
      "review_list = []\n",
      "\n",
      "# Проходим по всем найденным элементам\n",
      "for review in reviews:\n",
      "    # Извлекаем заголовок отзыва\n",
      "    title = review.find(\"h3\", class_=\"text-weight-medium text-size-3 ldecc766d\").text\n",
      "    # Извлекаем текст отзыва\n",
      "    text = review.find(\"div\", class_=\"lf4cbd87d l9656ec89 lfd76152f lced4cbee\").text\n",
      "    # Извлекаем дату отзыва\n",
      "    date = review.find(\"div\", class_=\"lf4cbd87d l9656ec89 lfd76152f l7dbc1646\").text\n",
      "    # Создаем объект отзыва\n",
      "    review_obj = {\"name\": title, \"full_descr\": text, \"date\": date}\n",
      "    # Добавляем объект в список\n",
      "    review_list.append(review_obj)\n",
      "\n",
      "# Выводим список отзывов\n",
      "print(review_list)\n",
      "```\n",
      "\n",
      "Этот код сначала загружает HTML-страницу, затем использует Beautiful Soup для разбора HTML и извлечения нужных элементов. В результате он создает список объектов, каждый из которых содержит название отзыва, его текст и дату.\n"
     ]
    }
   ],
   "source": [
    "# Результат можно копировать и запускать парсер\n",
    "print(gigahelp(url = url, query = query, auth_token = token, tag='la8a5ef73'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51336c6c",
   "metadata": {},
   "source": [
    "### Использование функции в режиме question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79eb01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Приведи пример кода на python для поиска инофрмации с сайта при помощи selenium и функции find_by_class_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd2580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот пример кода на Python, который использует Selenium для поиска информации на сайте с использованием метода `find_by_class_name`:\n",
      "\n",
      "```python\n",
      "from selenium import webdriver\n",
      "from selenium.webdriver.common.by import By\n",
      "from selenium.webdriver.support.ui import WebDriverWait\n",
      "from selenium.webdriver.support import expected_conditions as EC\n",
      "\n",
      "# Устанавливаем путь к драйверу браузера\n",
      "driver = webdriver.Chrome()\n",
      "\n",
      "# Открываем сайт\n",
      "driver.get(\"https://example.com\")\n",
      "\n",
      "# Ждем, пока страница загрузится\n",
      "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"your-class-name\")))\n",
      "\n",
      "# Получаем элемент по классу\n",
      "element = driver.find_element_by_class_name(\"your-class-name\")\n",
      "\n",
      "# Теперь вы можете работать с элементом\n",
      "print(element.text) # Выводим текст элемента\n",
      "```\n",
      "\n",
      "В этом примере мы используем `find_by_class_name` для поиска элемента на странице, который имеет класс `\"your-class-name\"`. После того как элемент найден, мы можем получить доступ к его атрибутам, таким как текст (`text`), и использовать их в коде.\n"
     ]
    }
   ],
   "source": [
    "print(gigahelp(url = url, query = query, auth_token = token, type_query = 'question'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118e2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
